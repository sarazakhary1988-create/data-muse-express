import { useState, useCallback } from 'react';
import { ResearchTask, ResearchResult, Report, useResearchStore } from '@/store/researchStore';
import { researchApi } from '@/lib/api/research';
import { toast } from '@/hooks/use-toast';

export const useResearchEngine = () => {
  const { 
    addTask, 
    updateTask, 
    addReport, 
    setIsSearching,
    setSearchQuery 
  } = useResearchStore();

  const extractDomain = (url: string): string => {
    try {
      const urlObj = new URL(url);
      return urlObj.hostname.replace('www.', '');
    } catch {
      return 'unknown';
    }
  };

  const calculateRelevanceScore = (item: any, query: string): number => {
    const queryLower = query.toLowerCase();
    const title = (item.title || '').toLowerCase();
    const description = (item.description || '').toLowerCase();
    const markdown = (item.markdown || '').toLowerCase();
    
    let score = 0.5;
    
    // Title contains query terms
    const queryWords = queryLower.split(/\s+/).filter(w => w.length > 2);
    for (const word of queryWords) {
      if (title.includes(word)) score += 0.15;
      if (description.includes(word)) score += 0.1;
      if (markdown.includes(word)) score += 0.05;
    }
    
    // Exact phrase match
    if (title.includes(queryLower)) score += 0.2;
    if (description.includes(queryLower)) score += 0.1;
    
    return Math.min(1, score);
  };

  const generateReport = async (query: string, results: ResearchResult[]): Promise<Report> => {
    // Combine all content for AI analysis
    const combinedContent = results
      .slice(0, 8)
      .map(r => `## ${r.title}\nSource: ${r.url}\n\n${r.content}`)
      .join('\n\n---\n\n');

    let reportContent = '';
    
    try {
      // Generate AI-powered report
      const analyzeResult = await researchApi.analyze(query, combinedContent, 'report');
      
      if (analyzeResult.success && analyzeResult.result) {
        reportContent = analyzeResult.result;
      } else {
        // Fallback to basic report
        reportContent = generateBasicReport(query, results);
      }
    } catch (error) {
      console.error('AI report generation failed:', error);
      reportContent = generateBasicReport(query, results);
    }

    const sections = [
      { id: 'content', title: 'Full Report', content: reportContent, order: 1 },
    ];

    return {
      id: `report-${Date.now()}`,
      title: `Research Report: ${query}`,
      taskId: '',
      format: 'markdown',
      content: reportContent,
      createdAt: new Date(),
      sections,
    };
  };

  const generateBasicReport = (query: string, results: ResearchResult[]): string => {
    const uniqueDomains = new Set(results.map(r => r.metadata.domain)).size;
    const avgRelevance = Math.round(results.reduce((acc, r) => acc + r.relevanceScore, 0) / results.length * 100);
    
    return `# Research Report: ${query}

## Executive Summary

This comprehensive research report analyzes "${query}" using AI-powered web research. We examined ${results.length} high-quality sources from ${uniqueDomains} unique domains.

---

## Key Findings

${results.slice(0, 5).map((r, i) => `### ${i + 1}. ${r.title}

${r.summary}

**Source**: [${r.metadata.domain}](${r.url})  
**Relevance**: ${Math.round(r.relevanceScore * 100)}%
`).join('\n')}

---

## Data Summary

| Metric | Value |
|--------|-------|
| Total Sources | ${results.length} |
| Average Relevance | ${avgRelevance}% |
| Unique Domains | ${uniqueDomains} |

---

## All Sources

${results.map((r, i) => `${i + 1}. [${r.title}](${r.url})`).join('\n')}

---

*Generated by NexusAI Research Engine on ${new Date().toLocaleDateString()}*
`;
  };

  const startResearch = useCallback(async (query: string) => {
    const taskId = `task-${Date.now()}`;
    
    const newTask: ResearchTask = {
      id: taskId,
      query,
      status: 'processing',
      progress: 0,
      results: [],
      createdAt: new Date(),
    };

    addTask(newTask);
    setIsSearching(true);

    try {
      // Step 1: Search the web
      updateTask(taskId, { progress: 10 });
      
      toast({
        title: "Searching the web...",
        description: `Finding sources for: ${query}`,
      });

      const searchResult = await researchApi.search(query, 10, true);
      
      updateTask(taskId, { progress: 40 });

      if (!searchResult.success || !searchResult.data) {
        throw new Error(searchResult.error || 'Search failed');
      }

      // Step 2: Process search results
      toast({
        title: "Processing results...",
        description: `Found ${searchResult.data.length} sources`,
      });

      updateTask(taskId, { progress: 60 });

      // Transform search results to ResearchResult format
      const results: ResearchResult[] = searchResult.data.map((item, index) => ({
        id: `result-${Date.now()}-${index}`,
        title: item.title || 'Untitled',
        url: item.url,
        content: item.markdown || item.description || '',
        summary: item.description || (item.markdown ? item.markdown.substring(0, 300) + '...' : 'No summary available'),
        relevanceScore: calculateRelevanceScore(item, query),
        extractedAt: new Date(),
        metadata: {
          domain: extractDomain(item.url),
          wordCount: item.markdown?.split(/\s+/).length || 0,
        },
      }));

      // Sort by relevance
      results.sort((a, b) => b.relevanceScore - a.relevanceScore);

      updateTask(taskId, { progress: 75, results });

      // Step 3: Generate AI report
      toast({
        title: "Generating report...",
        description: "AI is analyzing the research data",
      });

      const report = await generateReport(query, results);
      
      updateTask(taskId, { progress: 100 });

      // Complete the task
      updateTask(taskId, {
        status: 'completed',
        progress: 100,
        results,
        completedAt: new Date(),
      });

      addReport({ ...report, taskId });
      setSearchQuery('');

      toast({
        title: "Research Complete",
        description: `Analyzed ${results.length} sources and generated a comprehensive report.`,
      });

      return { task: newTask, results, report };
    } catch (error) {
      console.error('Research error:', error);
      
      updateTask(taskId, {
        status: 'failed',
        progress: 0,
      });

      const errorMessage = error instanceof Error ? error.message : 'Unknown error';
      
      toast({
        title: "Research Failed",
        description: errorMessage,
        variant: "destructive",
      });

      throw error;
    } finally {
      setIsSearching(false);
    }
  }, [addTask, updateTask, addReport, setIsSearching, setSearchQuery]);

  // Deep research - scrapes specific URLs
  const deepScrape = useCallback(async (url: string) => {
    toast({
      title: "Scraping...",
      description: `Extracting content from ${url}`,
    });

    const result = await researchApi.scrape(url);
    
    if (!result.success) {
      toast({
        title: "Scrape Failed",
        description: result.error || 'Failed to scrape URL',
        variant: "destructive",
      });
      return null;
    }

    toast({
      title: "Scrape Complete",
      description: `Successfully extracted content from ${extractDomain(url)}`,
    });

    return result;
  }, []);

  // Map a website to discover URLs
  const mapWebsite = useCallback(async (url: string, searchTerm?: string) => {
    toast({
      title: "Mapping website...",
      description: `Discovering URLs on ${url}`,
    });

    const result = await researchApi.map(url, searchTerm);
    
    if (!result.success) {
      toast({
        title: "Map Failed",
        description: result.error || 'Failed to map website',
        variant: "destructive",
      });
      return null;
    }

    toast({
      title: "Map Complete",
      description: `Found ${result.links?.length || 0} URLs`,
    });

    return result;
  }, []);

  return { 
    startResearch, 
    deepScrape, 
    mapWebsite 
  };
};
