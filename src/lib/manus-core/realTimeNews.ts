/**
 * Real-Time News Engine - ACTUAL IMPLEMENTATION
 * 
 * Autonomous news fetching using 7+ real data sources
 * Integrates: RSS Parser, Crawl4AI, Web Scrapers
 * Uses: Local LLMs (DeepSeek, Llama via Ollama)
 * 
 * NO mock, synthetic, or dummy data - 100% REAL-TIME DATA
 */

import axios from 'axios';
import * as cheerio from 'cheerio';

export interface NewsArticle {
    id: string;
    title: string;
    url: string;
    source: string;
    content: string;
    publishedAt: Date;
    category: string;
    sentiment?: 'positive' | 'neutral' | 'negative';
    images?: string[];
    authors?: string[];
}

export interface NewsSource {
    name: string;
    url: string;
    type: 'rss' | 'web' | 'api';
    updateInterval: number;
}

/**
 * Initialize news sources
 */
const newsSources: NewsSource[] = [
    // Major News RSS Feeds
  { name: 'BBC News', url: 'http://feeds.bbc.co.uk/news/rss.xml', type: 'rss', updateInterval: 300000 },
  { name: 'Reuters', url: 'https://feeds.reuters.com/reuters/businessNews', type: 'rss', updateInterval: 300000 },
  { name: 'Bloomberg', url: 'https://www.bloomberg.com/feed/podcast/etf-report.xml', type: 'rss', updateInterval: 300000 },
  { name: 'CNBC', url: 'https://www.cnbc.com/id/100003114/device/rss/rss.html', type: 'rss', updateInterval: 300000 },
  { name: 'TechCrunch', url: 'http://feeds.feedburner.com/TechCrunch/', type: 'rss', updateInterval: 300000 },
  { name: 'Hacker News', url: 'https://news.ycombinator.com/rss', type: 'rss', updateInterval: 300000 },
  { name: 'Google News Tech', url: 'https://news.google.com/rss/topics/CAAqJQgKIR5BVVNLUS1CRWFnQjBGV2EyOEExQjBGV2FnQjBDakkaGAoXQ0JBU0hRb0pMN21rTWVBTUF3QjBGV2EyOHA', type: 'rss', updateInterval: 300000 },
  ];

/**
 * Fetch news using RSS parser
 */
export async function fetchNewsViaRSS(source: NewsSource): Promise<NewsArticle[]> {
    try {
          const response = await axios.get(source.url, { timeout: 10000 });
          const $ = cheerio.load(response.data);
          const articles: NewsArticle[] = [];

      // Parse RSS/Atom feed
      $('item, entry').each((index, elem) => {
              const $item = $(elem);
              const title = $item.find('title').first().text();
              const link = $item.find('link').first().attr('href') || $item.find('link').first().text();
              const description = $item.find('description, summary').first().text();
              const pubDate = $item.find('pubDate, published').first().text();

                                  if (title && link) {
                                            articles.push({
                                                        id: `${source.name}-${index}`,
                                                        title: title.substring(0, 200),
                                                        url: link,
                                                        source: source.name,
                                                        content: description.substring(0, 1000),
                                                        publishedAt: new Date(pubDate),
                                                        category: extractCategory(title + ' ' + description),
                                                        images: extractImages($item),
                                                        authors: extractAuthors($item),
                                            });
                                  }
      });

      return articles;
    } catch (error) {
          console.error(`Error fetching from ${source.name}:`, error);
          return [];
    }
}

/**
 * Fetch news using Crawl4AI for dynamic content
 */
export async function fetchNewsViaCrawl4AI(url: string): Promise<NewsArticle[]> {
    try {
          // Crawl4AI integration - using Playwright-based scraping
      const response = await axios.post('http://localhost:8000/crawl', {
              url,
              wait_for: '[data-article]',
              remove_overlay: true,
      });

      const articles: NewsArticle[] = [];
          const $ = cheerio.load(response.data.html);

      $('[data-article]').each((index, elem) => {
              const $article = $(elem);
              const title = $article.find('[data-title]').text();
              const link = $article.find('a').attr('href');
              const content = $article.find('[data-content]').text();

                                     if (title && link) {
                                               articles.push({
                                                           id: `crawl4ai-${index}`,
                                                           title,
                                                           url: link,
                                                           source: 'Crawl4AI',
                                                           content,
                                                           publishedAt: new Date(),
                                                           category: extractCategory(title + ' ' + content),
                                               });
                                     }
      });

      return articles;
    } catch (error) {
          console.error('Crawl4AI fetch error:', error);
          return [];
    }
}

/**
 * Fetch news using web scraping
 */
export async function fetchNewsViaWebScraper(url: string, selectors: {
    article: string;
    title: string;
    link: string;
    content: string;
}): Promise<NewsArticle[]> {
    try {
          const response = await axios.get(url, { 
                                                 headers: { 'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36' },
                  timeout: 10000,
          });

      const $ = cheerio.load(response.data);
          const articles: NewsArticle[] = [];

      $(selectors.article).each((index, elem) => {
              const $elem = $(elem);
              const title = $elem.find(selectors.title).text();
              const link = $elem.find(selectors.link).attr('href');
              const content = $elem.find(selectors.content).text();

                                      if (title && link) {
                                                articles.push({
                                                            id: `scraper-${url}-${index}`,
                                                            title,
                                                            url: link.startsWith('http') ? link : new URL(link, url).toString(),
                                                            source: new URL(url).hostname || 'Unknown',
                                                            content,
                                                            publishedAt: new Date(),
                                                            category: extractCategory(title + ' ' + content),
                                                });
                                      }
      });

      return articles;
    } catch (error) {
          console.error(`Web scraping error for ${url}:`, error);
          return [];
    }
}

/**
 * Fetch all news from configured sources
 */
export async function fetchAllRealTimeNews(): Promise<NewsArticle[]> {
    console.log('ðŸ”„ Fetching real-time news from all sources...');

  const allArticles: NewsArticle[] = [];

  // Fetch from all RSS sources in parallel
  const rssPromises = newsSources.map(source => fetchNewsViaRSS(source));
    const rssResults = await Promise.all(rssPromises);

  rssResults.forEach(articles => allArticles.push(...articles));

  console.log(`âœ… Fetched ${allArticles.length} articles from real-time sources`);

  return allArticles;
}

/**
 * Categorize news with local LLM (DeepSeek/Llama via Ollama)
 */
export async function categorizeNewsWithAI(article: NewsArticle): Promise<string> {
    try {
          // Call local Ollama LLM (DeepSeek or Llama)
      const response = await axios.post('http://localhost:11434/api/generate', {
              model: 'deepseek-coder', // or 'llama2', 'neural-chat', etc.
              prompt: `Categorize this news article in ONE word (Technology, Business, Politics, Sports, Health, Science, Entertainment, Other):\n\nTitle: ${article.title}\nContent: ${article.content.substring(0, 500)}`,
              stream: false,
      });

      const category = response.data.response.split('\n')[0].trim().split(' ')[0];
          return category || 'Other';
    } catch (error) {
          // Fallback to keyword-based categorization
      return extractCategory(article.title + ' ' + article.content);
    }
}

/**
 * Extract entities from news (people, companies, locations)
 */
export async function extractEntitiesWithAI(article: NewsArticle): Promise<{
    people: string[];
    companies: string[];
    locations: string[];
}> {
    try {
          const response = await axios.post('http://localhost:11434/api/generate', {
                  model: 'deepseek-coder',
                  prompt: `Extract entities from this text. Return JSON format only.\n\nText: ${article.content.substring(0, 500)}`,
                  stream: false,
          });

      const result = JSON.parse(response.data.response);
          return result;
    } catch (error) {
          return { people: [], companies: [], locations: [] };
    }
}

/**
 * Get news summary using local LLM
 */
export async function generateNewsSummary(articles: NewsArticle[]): Promise<string> {
    if (articles.length === 0) return 'No articles to summarize.';

  const articleText = articles
      .slice(0, 5)
      .map(a => `${a.title}: ${a.content.substring(0, 200)}`)
      .join('\n\n');

  try {
        const response = await axios.post('http://localhost:11434/api/generate', {
                model: 'deepseek-coder', // or 'llama2:7b'
                prompt: `Summarize these news articles in 2-3 sentences:\n\n${articleText}`,
                stream: false,
        });

      return response.data.response;
  } catch (error) {
        console.error('Summarization error:', error);
        return 'Unable to generate summary.';
  }
}

/**
 * Filter news by category
 */
export function filterNewsByCategory(articles: NewsArticle[], category: string): NewsArticle[] {
    return articles.filter(a => a.category.toLowerCase() === category.toLowerCase());
}

/**
 * Helper: Extract category from text
 */
function extractCategory(text: string): string {
    const categories = ['Technology', 'Business', 'Politics', 'Sports', 'Health', 'Science', 'Entertainment'];
    const lowerText = text.toLowerCase();

  for (const cat of categories) {
        if (lowerText.includes(cat.toLowerCase())) return cat;
  }

  return 'Other';
}

/**
 * Helper: Extract images from RSS item
 */
function extractImages(elem: any): string[] {
    const images: string[] = [];
    elem.find('image, media\\:content, enclosure').each((_: number, el: any) => {
          const url = elem(el).attr('url') || elem(el).attr('href');
          if (url) images.push(url);
    });
    return images;
}

/**
 * Helper: Extract authors from RSS item
 */
function extractAuthors(elem: any): string[] {
    const authors: string[] = [];
    const author = elem.find('author, creator, dc\\:creator').text();
    if (author) authors.push(author);
    return authors;
}

/**
 * Search news by keyword
 */
export function searchNews(articles: NewsArticle[], keyword: string): NewsArticle[] {
    const lowerKeyword = keyword.toLowerCase();
    return articles.filter(a => 
                               a.title.toLowerCase().includes(lowerKeyword) || 
                               a.content.toLowerCase().includes(lowerKeyword)
                             );
}

/**
 * Get trending topics
 */
export function getTrendingTopics(articles: NewsArticle[], topN: number = 5): string[] {
    const words: { [key: string]: number } = {};

  articles.forEach(article => {
        const text = (article.title + ' ' + article.content).toLowerCase();
        const tokens = text.split(/\s+/).filter(t => t.length > 3);

                       tokens.forEach(token => {
                               words[token] = (words[token] || 0) + 1;
                       });
  });

  return Object.entries(words)
      .sort((a, b) => b[1] - a[1])
      .slice(0, topN)
      .map(([word]) => word);
}

/**
 * Export news to JSON
 */
export function exportNewsToJSON(articles: NewsArticle[]): string {
    return JSON.stringify(articles, null, 2);
}

/**
 * Initialize real-time news fetching
 */
export async function startRealTimeNewsFetching(intervalMs: number = 300000): Promise<NodeJS.Timer> {
    const fetchAndProcess = async () => {
          const articles = await fetchAllRealTimeNews();

          // Process with local LLM
          for (const article of articles) {
                  article.category = await categorizeNewsWithAI(article);
          }

          console.log(`âœ… Processed ${articles.length} articles with AI categorization`);
          return articles;
    };

  // Initial fetch
  await fetchAndProcess();

  // Schedule periodic updates
  return setInterval(fetchAndProcess, intervalMs);
}
